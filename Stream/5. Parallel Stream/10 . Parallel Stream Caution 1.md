-----
### 병렬 스트림 사용시 주의점 1
-----
1. 스트림에 parallel() 추가하면 병렬 스트림
2. 병렬 스트림은 Fork / Join 공용 풀 사용
3. Fork / Join 공용 풀은 CPU 바운드 작업(계산 집약적 작업)을 위해 설계
4. 따라서, 스레드가 주로 대기해야하는 I/O 바운드 작업에는 적합하지 않음
   - I/O 바운드 작업은 주로 네트워크 호출을 통한 대기 발생 (예) 외부 API 호출, 데이터베이스 조회)

5. 주의사항 - Fork / Join 프레임워크는 CPU 바운드 작업에만 사용
   - Fork / Join 프레임워크는 주로 CPU 바운드 작업(계산 집약적 작업)을 처리하기 위해 설계
   - 이러한 작업은 CPU 사용률이 높고 I/O 대기 시간이 적음
   - CPU 바운드 작업의 경우, 물리적 CPU 코어와 비슷한 수의 스레드를 사용하는 것이 최적 성능 발휘 가능
   - 스레드 수가 코어 수보다 많아지면 컨텍스트 스위치 비용이 증가하고, 스레드 간 경쟁으로 인해 오히려 성능 저하 될 수 있음

6. 따라서, I/O 처럼 블로킹 대기 시간이 긴 작업을 ForkJoinPool에서 처리하면 다음과 같은 문제 발생
   - 스레드 블로킹에 따른 CPU 낭비
     + ForkJoinPool은 CPU 코어 수에 맞춰 제한된 개수의 스레드를 사용 (특히 공용 풀)
     + I/O 작업으로 스레드가 블로킹되면 CPU가 놀게 되어, 전체 병렬 처리 효율이 크게 떨어짐

   - 컨텍스트 스위칭 오버헤드 증가
     + I/O 작업 때문에 스레드를 늘리면, 실제 연산보다 대기 시간이 길어지는 상황이 발생할 수 있음
     + 스레드가 많아질수록 컨텍스트 스위칭(context switching) 비용도 증가하여 오히려 성능이 떨어질 수 있음

   - 작업 훔치기 기법 무력화
     + ForkJoinPool이 제공하는 작업 훔치기 알고리즘은, CPU 바운드 작업에서 빠르게 작업 단위를 계속 처리하도록 설계 (작업을 훔쳐서 쉬는 스레드 없이 계속 작업)
     + I/O 대기 시간이 많은 작업은 스래드가 I/O로 인해 대기하고 있는 경우가 많아, 작업 훔치기가 빛을 발휘하기 어렵고, 결과적으로 병렬 처리의 장점을 살리기 어려움

   - 분할-정복(작업 분할) 이점 감소
     + Fork/Join 방식을 통해 작업을 잘게 나누어도, I/O 병목이 발생하면 CPU 병렬화 이점이 크게 줄어듬
     + 오히려 분할된 작업들이 각기 I/O 대기를 반복하면서, fork(), join()에 따른 오버헤드만 증가할 수 있음

7. 정리
   - 공용 풀(Common Pool)은 Fork/Join 프레임워크의 편리한 기능으로, 별도의 풀 생성 없이도 효율적인 병렬 처리를 가능하게 함
   - 하지만 블로킹 작업이나 특수한 설정이 필요한 경우에는 커스텀 풀을 고려
      + CPU 바운드 작업이라면 ForkJoinPool을 통해 병렬 계산을 극대화할 수 있지만, I/O 바운드 작업은 별도의 전용 스레드 풀을 사용하는 편이 더 적합
      + 예) Executors.newFixedThreadPool() 등

-----
### 병렬 스트림 - 예제 5
-----
1. 여러 요청이 동시에 들어올 때, 공용 풀에서 발생할 수 있는 문제
2. 시나리오
   - 여러 사용자가 동시에 서버를 호출하는 상황
   - 각 요청은 병렬 스트림을 사용하여 몇 가지 무거운 작업을 처리
   - 모든 요청이 동일한 공용 풀(ForkJoinPool.commonPool)을 공유

3. ParallelMain5
```java
package parallel;

import util.MyLogger;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.IntStream;

import static util.MyLogger.log;

public class ParallelMain5 {
    public static void main(String[] args) throws InterruptedException {
        // 병렬 수준 3으로 제한 - 최대 가능 스레드 수 3개 + 메인 스레드 1게 = 4개
        System.setProperty("java.util.concurrent.ForkJoinPool.common.parallelism", "3");

        // 요청 풀 추가
        ExecutorService requestPool = Executors.newFixedThreadPool(100);
        int nThreads = 3; // 1, 2, 3, 10, 20 (요청 스레드)

        for(int i = 1; i <= nThreads; i++) {
            String requestName = "request " + i;
            requestPool.submit(() -> logic(requestName));
            Thread.sleep(100); // 스레드 순서 확인을 위해 약간 대기
        }
        requestPool.close();
    }

    private static void logic(String requestName) {
        log("[" + requestName + "] START");
        long startTime = System.currentTimeMillis();

        int sum = IntStream.rangeClosed(1, 4)
                .parallel()
                .map(i -> HeavyJob.heavyTask(i, requestName))
                .reduce(0, (a, b) -> a + b);

        long endTime = System.currentTimeMillis();
        log("[" + requestName + "] time : " + (endTime - startTime) + "ms, sum : " + sum);
    }
}
```
  - CPU 코어가 4개라고 가정 (시스템 속성을 사용해 공용 풀의 병렬 수준을 3으로 제한)
    + 공용 풀 스레드 수가 3개
  - 예제 단순화를 위해 1 ~ 4 범위의 작업 처리
  - requestPool은 여러 사용자 요청을 시뮬레이션하기 위한 스레드 풀
  - 각 요청은 logic() 메서드 안에서 parallel() 스트림을 사용하며 작업 처리 (이 때, 공용 풀 사용)

```
20:00:14.437 [pool-1-thread-1] [request 1] START
20:00:14.462 [ForkJoinPool.commonPool-worker-3] [request 1]1 -> 10
20:00:14.462 [ForkJoinPool.commonPool-worker-1] [request 1]2 -> 20
20:00:14.462 [pool-1-thread-1] [request 1]3 -> 30
20:00:14.462 [ForkJoinPool.commonPool-worker-2] [request 1]4 -> 40
20:00:14.480 [pool-1-thread-2] [request 2] START
20:00:14.481 [pool-1-thread-2] [request 2]3 -> 30
20:00:14.590 [pool-1-thread-3] [request 3] START
20:00:14.591 [pool-1-thread-3] [request 3]3 -> 30
20:00:15.470 [ForkJoinPool.commonPool-worker-2] [request 2]2 -> 20
20:00:15.470 [ForkJoinPool.commonPool-worker-1] [request 2]4 -> 40
20:00:15.472 [ForkJoinPool.commonPool-worker-3] [request 3]2 -> 20
20:00:15.476 [pool-1-thread-1] [request 1] time : 1029ms, sum : 100
20:00:15.495 [pool-1-thread-2] [request 2]1 -> 10
20:00:15.603 [pool-1-thread-3] [request 3]4 -> 40
20:00:16.476 [ForkJoinPool.commonPool-worker-3] [request 3]1 -> 10
20:00:16.507 [pool-1-thread-2] [request 2] time : 2026ms, sum : 100
20:00:17.489 [pool-1-thread-3] [request 3] time : 2898ms, sum : 100
```
<div align="center">
<img src="https://github.com/user-attachments/assets/c8f7b7a9-4774-4489-b433-bc4062b950a1">
</div>

<div align="center">
<img src="https://github.com/user-attachments/assets/93d41c8d-da12-42c3-a4b7-c7b4f888b9c7">
</div>

  - 공용 풀의 제한된 병렬성
    + 공용 풀은 병렬 수준(parallelism)이 3으로 설정되어 있어, 최대 3개의 작업만 동시에 처리할 수 있음
    + 여기에 요청 스레드도 자신의 작업에 참여하므로 각 작업당 총 4개의 스레드만 사용
    + 따라서 총 12개의 요청(각각 4개의 작업)을 처리하는데 필요한 스레드 자원이 부족

  - 처리 시간의 불균형
    + request1: 1012ms (약 1초)
    + request2: 1931ms (약 2초)
    + request3: 2836ms (약 3초)
    + 첫 번째 요청은 거의 모든 공용 풀 워커를 사용할 수 있었지만, 이후 요청들은 제한된 공용 풀 자원을 두고 경쟁해야 함
    + 따라서 완료 시간이 점점 느려짐

  - 스레드 작업 분배
    + 일부 작업은 요청 스레드(pool-1-thread-N)에서 직접 처리되고, 일부는 공용 풀(ForkJoinPool.commonPool-worker-N)에서 처리
    + 요청 스레드가 작업을 도와주지만, 공용 풀의 스레드가 매우 부족하기 때문에 한계가 있음

  - 요청이 증가할수록 이 문제는 더 심각해짐
  - nThreads의 숫자를 늘려서 동시 요청을 늘리면, 응답 시간이 확연하게 늘어나는 것을 확인할 수 있음

4. 핵심 문제점
   - 공용 풀 병목 현상 : 모든 병렬 스트림이 동일한 공용 풀을 공유하므로, 요청이 많아질수록 병목 현상이 발생
   - 자원 경쟁 : 여러 요청이 제한된 스레드 풀을 두고 경쟁하면서 요청의 성능이 저하
   - 예측 불가능한 성능 : 같은 작업이라도 동시에 실행되는 다른 작업의 수에 따라 처리 시간이 크게 달라짐

5. 특히 실무 환경에서는 주로 여러 요청을 동시에 처리하는 애플리케이션 서버를 사용하게 됨
   - 이때 수 많은 요청이 공용 풀을 사용하는 것은 매우 위험할수 있음
   - 따라서 병렬 스트림을 남용하면 전체 시스템 성능이 저하될 수 있음
   - nThreads를 너무 늘리는 것 보다, 차라리 parallel()을 제거하는 것이 작업이 더 빨리 처리 될 수 있음
   - nThreads를 20으로 설정한 다음 실행해보면 매우 느린 응답을 확인할 수 있음
   - 이때 차라리 parallel()을 제거하면 더 빠른 응답을 확인할 수 있음

6. 참고로 이번 예제에서 사용한 heavyTask()는 1초간 스레드가 대기하는 작업
   - 따라서 I/O 바운드 작업에 가까움
   - 이런 종류의 작업은 Fork/Join 공용 풀 보다는 별도의 풀을 사용하는 것이 좋음

7. 💡 주의 사항
   - 주의 : 실무에서 공용 풀은 절대 I/O 바운드 작업을 하면 안 됨
     + 실무에서 공용 풀에 I/O 바운드 작업을 해서 장애가 나는 경우가 있음
     + CPU 코어가 4개라면 공용 풀은 3개의 스레드만 사용한다. 그리고 공용 풀을 애플리케이션 전체에서 사용
     + 공용 풀에 있는 스레드 3개가 I/O 바운드 작업으로 대기하는 순간, 애플리케이션에서 공용 풀을 사용하는 모든 요청이 다 밀리게 됨
     + 예를 들어 공용 풀을 통해 외부 API를 호출하거나 데이터베이스를 호출하고 기다리는 경우가 있음
     + 만약 외부 API나 데이터베이스의 응답이 늦게 온다면 공용 풀의 3개의 스레드가 모두 I/O 응답을 대기
     + 그리고 나머지 모든 요청이 공용 풀의 스레드를 기다리며 다 밀리게 되는 무시무시한 일이 발생

   - 공용 풀은 반드시 CPU 바운드(계산 집약적인) 작업에만 사용
     + 병렬 스트림은 처음부터 Fork/Join 공용 풀을 사용해서 CPU 바운드 작업에 맞도록 설계
     + 따라서 이런 부분을 잘 모르고 실무에서 병렬 스트림에 I/O 대기 작업을 하는 것은 아주 위험한 일
     + 특히 병렬 스트림의 경우 단순히 parallel() 한 줄만 추가하면 병렬 처리가 되기 때문에, 어떤 스레드가 사용되는지도 제대로 이해하지 못하고 사용하는 경우가 있음
     + 병렬 스트림은 반드시 CPU 바운드 작업에만 사용
 
