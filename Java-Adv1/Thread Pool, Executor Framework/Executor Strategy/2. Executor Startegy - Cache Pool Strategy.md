-----
### Executor 전략 - 캐시 풀 전략
-----
1. new CachedThreadPool()
   - 기본 스레드를 사용하지 않고, 60초 생존 주기를 가진 초과 스레드만 사용
   - 초과 스레드의 수는 제한이 없음
   - 큐에 작업을 저장하지 않음 (SynchronousQueue)
      + 대신에 생산자의 요청을 스레드 풀의 소비자 스레드가 직접 받아서 바로 처리
   - 모든 요청이 대기하지 않고 스레드가 바로 처리하므로, 따라서 빠른 처리가 가능

```java
new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
```

2. SynchronousQueue
   - BlockingQueue 인터페이스의 구현체 중 하나
   - 이 큐는 내부에 저장 공간이 없으며, 대신에 생산자의 작업을 소비자 스레드에게 직접 전달
   - 쉽게 이야기해서 저장 공간의 크기가 0이고, 생산자 스레드가 큐가 작업을 전달하면 소비자 스레드가 큐에서 작업을 꺼낼 때 까지 대기
   - 소비자 작업을 요청하면 기다리던 생산자가 소비자에게 직접 작업을 전달하고 반환하며, 그 반대의 경우도 같음
   - 이름 그대로 생산자와 소비자를 동기화하는 큐
   - 쉽게 이야기해서 중간에 버퍼를 두지 않는 스레드간 직거래라고 생각

3. PoolSizeMainV3
```java
package thread.executor.poolsize;

import thread.executor.RunnableTask;

import java.util.concurrent.*;

import static thread.executor.ExecutorUtils.printState;
import static thread.util.MyLogger.log;
import static thread.util.ThreadUtils.sleep;

public class PoolSizeMainV3 {
    public static void main(String[] args) {
        // ExecutorService es = Executors.newCachedThreadPool();
        ExecutorService es = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 3, TimeUnit.SECONDS, new SynchronousQueue<>());

        log("pool 생성");
        printState(es);

        for(int i = 1; i <= 4; i++) {
            String taskName = "task " + i;
            es.execute(new RunnableTask(taskName));
            printState(es, taskName);
        }

        sleep(3000);
        log("== 작업 수행 완료 ==");
        printState(es);

        sleep(3000);
        log("== maximumPoolSize 대기 시간 초과");
        printState(es);
        
        es.close();
        log("== shutdown 완료 ==");
        printState(es);
    }
}
```
  - 캐시 스레드 풀 전략은 초과 스레드가 60초 생존 주기를 가지지만, 확인을 위해 3초로 수정
  - 실행 결과
```
17:07:15.560 [     main] pool 생성
17:07:15.578 [     main] [pool = 0, active = 0, queuedTasks = 0, completedTask = 0]
17:07:15.584 [pool-1-thread-1] task 1 시작
17:07:15.591 [     main] task 1 -> [pool = 1, active = 1, queuedTasks = 0, completedTask = 0]
17:07:15.592 [     main] task 2 -> [pool = 2, active = 2, queuedTasks = 0, completedTask = 0]
17:07:15.592 [pool-1-thread-2] task 2 시작
17:07:15.592 [     main] task 3 -> [pool = 3, active = 3, queuedTasks = 0, completedTask = 0]
17:07:15.592 [pool-1-thread-3] task 3 시작
17:07:15.594 [     main] task 4 -> [pool = 4, active = 4, queuedTasks = 0, completedTask = 0]
17:07:15.594 [pool-1-thread-4] task 4 시작
17:07:16.594 [pool-1-thread-2] task 2 완료
17:07:16.594 [pool-1-thread-1] task 1 완료
17:07:16.609 [pool-1-thread-4] task 4 완료
17:07:16.609 [pool-1-thread-3] task 3 완료
17:07:18.601 [     main] == 작업 수행 완료 ==
17:07:18.601 [     main] [pool = 4, active = 0, queuedTasks = 0, completedTask = 4]
17:07:21.612 [     main] == maximumPoolSize 대기 시간 초과
17:07:21.612 [     main] [pool = 0, active = 0, queuedTasks = 0, completedTask = 4]
17:07:21.612 [     main] == shutdown 완료 ==
17:07:21.613 [     main] [pool = 0, active = 0, queuedTasks = 0, completedTask = 4]
```

  - 모든 작업이 대기하지 않고 작업의 수 만큼 스레드가 생기면서 바로 실행되는 것을 확인
  - 'maximumPoolSize 대기 시간 초과' 로그를 통해 초과 스레드가 대기 시간이 지나서 모두 사라진 것을 확인

4. 특징
   - 캐시 스레드 풀 전략은 매우 빠르고, 유연한 전략
   - 이 전략은 기본 스레드도 없고, 대기 큐에 작업도 쌓이지 않음
   - 대신에 작업 요청이 오면 초과 스레드로 작업을 바로 처리하므로, 따라서 빠른 처리가 가능
   - 초과 스레드의 수도 제한이 없기 때문에 CPU, 메모리 자원만 허용한다면 시스템의 자원을 최대로 사용할 수 있음
   - 추가로 초과 스레드는 60초간 생존하기 때문에 작업 수에 맞추어 적절한 수의 스레드가 재사용
   - 이런 특징 때문에 요청이 갑자기 증가하면 스레드도 갑자기 증가하고, 요청이 줄어들면 스레드도 점점 줄어듬
  - 이 전략은 작업의 요청 수에 따라서 스레드도 증가하고 감소하므로, 매우 유연한 전략

5. 기본 스레드 없이 초과 스레드만 만드는 방법
   - Executor 스레드 풀 관리
     + 작업을 요청하면 core 사이즈 만큼 스레드를 생성
         * core 사이즈가 없으므로, 바로 core 사이즈를 초과
     + core 사이즈를 초과하면 큐에 작업을 넣음
         * 큐에 작업을 넣을 수 없음 (SynchronousQueue는 큐의 저장 공간이 0인 특별한 큐)
     + 큐를 초과하면 max 사이즈 만큼 스레드를 만들며, 임시로 사용되는 초과 스레드가 생성
         * 초과 스레드가 생성되며, 물론 풀에 대기하는 초과 스레드가 있으면 재사용
     + max 사이즈를 초과하면 요청을 거절하여, 예외가 발생
         * 참고로 max 사이즈가 무제한이므로, 따라서 초과 스레드를 무제한으로 만들 수 있음
  - 결과적으로 이 전략의 모든 작업은 초과 스레드가 처리

6. 주의
   - 이 방식은 작업 수에 맞추어 스레드 수가 변하기 때문에, 작업의 처리 속도가 빠르고, CPU, 메모리를 매우 유연하게 사용할 수 있다는 장
   - 하지만 상황에 따라서 장점이 가장 큰 단점
      + 상황1 - 점진적인 사용자 확대
         * 개발한 서비스가 잘 되어서 사용자가 점점 늘어남
         * 캐시 스레드 전략을 사용하면 이런 경우 크게 문제가 되지 않음
         * 캐시 스레드 전략은 이런 경우에는 문제를 빠르게 찾을 수 있음
         * 사용자가 점점 증가하면서 스레드 사용량도 함께 늘어나므로 CPU 메모리의 사용량도 자연스럽게 증가
         * 물론 CPU, 메모리 자원은 한계가 있기 때문에 적절한 시점에 시스템을 증설해야 함
         * 그렇지 않으면 CPU, 메모리 같은 시스템 자원을 너무 많이 사용하면서 시스템이 다운될 수 있음

      + 상황2 - 갑작스런 요청 증가
         * 마케팅 팀의 이벤트가 대성공 하면서 갑자기 사용자가 폭증하여 고객은 응답을 받지 못한다고 항의
         * 개발자는 급하게 CPU, 메모리 사용량을 확인해보는데, CPU 사용량이 100%이고, 메모리 사용량도 지나치게 높아져있음
         * 스레드 수를 확인해보니 스레드가 수 천개 실행되고 있으며, 너무 많은 스레드가 작업을 처리하면서 시스템 전체가 느려지는 현상이 발생
         * 캐시 스레드 풀 전략은 스레드가 무한으로 생성될 수 있음
         * 수 천개의 스레드가 처리하는 속도 보다 더 많은 작업이 들어옴
         * 시스템은 너무 많은 스레드에 잠식 당해서 거의 다운되며, 메모리도 거의 다 사용되어 버림
         * 시스템이 멈추는 장애가 발생

7. 고정 스레드 풀 전략은 서버 자원은 여유가 있는데, 사용자만 점점 느려지는 문제가 발생할 수 있지만, 반면에 캐시 스레드 풀 전략은 서버의 자원을 최대한 사용하지만, 서버가 감당할 수 있는 임계점을 넘는 순간 시스템이 다운될 수 있음
